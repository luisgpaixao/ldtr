if(is.null(error_code(req))){
return(NULL)
}
reqParse = httr::content(req, as="parsed")
reqParse = parse_null(reqParse, parcelID)
return(reqParse)
}
# COMPLETAR
getSoilData = function(parcelID=133320){
URL = "https://taskmanager.agroinsider.com/data_co2/ForestProduction/"
URL = paste0(URL, parcelID, "/?format=json")
req = GET( URL )
if(is.null(error_code(req))){
return(NULL)
}
reqParse = httr::content(req, as="parsed")
reqParse = parse_null(reqParse, parcelID)
name = reqParse[[1]]$parcel
fp_samp = sample$ForestProductionSamplesSoil
for(sample in fp_samp){
zone = sample$zone
qrcode = sample$evidences_attachments
}
reqParse = reqParse[[1]]$ForestProductionSamplesSoil
if(length(reqParse)==0){
print( paste0("Missing Soil Sample: ", parcelID))
return(NULL)
}
length(reqParse)
}
check_soilSample = function(parcelID=131115){
URL = "https://taskmanager.agroinsider.com/data_co2/ForestProduction/"
URL = paste0(URL, parcelID, "/?format=json")
req = GET( URL )
if(is.null(error_code(req))){
return(NULL)
}
reqParse = httr::content(req, as="parsed")
reqParse = parse_null(reqParse, parcelID)
reqParse = reqParse[[1]]$ForestProductionSamplesSoil
if(length(reqParse)==0){
print( paste0("Missing Soil Sample: ", parcelID))
return(NULL)
}
df = data.frame(stringsAsFactors = F)
for(i in 1:length(reqParse)){
aux = reqParse[[i]]
zone = aux$zone
mo = aux$data_soil[[which(sapply(aux$data_soil, function(x) "Matéria orgânica - POS.007/Cálculo" %in% x))]]
mo = mo$result
areia = aux$data_soil[[which(sapply(aux$data_soil, function(x) "Granulometria - Areia - POS.028/Gravimetria" %in% x))]]
areia = areia$result
argila = aux$data_soil[[which(sapply(aux$data_soil, function(x) "Granulometria - Argila - POS.028/Gravimetria" %in% x))]]
argila = argila$result
limo = aux$data_soil[[which(sapply(aux$data_soil, function(x) "Granulometria - Limo - Argila - POS.028/Gravimetria" %in% x))]]
limo = limo$result
df = rbind(df, c(zone, mo, areia, argila, limo))
}
if(ncol(df) != 5){
print( paste0(parcelID, " !!! Adicionar zona na Prod. Florestal !!!" ))
}
names(df) = c("Zona", "MO", "Areia", "Argila", "Limo")
return(df)
}
# escape string
escape_str = function(str){
return( paste0('"', str, '"') )
}
# ll = list()
# for(i in vee){
#   geo = getWKTgeo(i)
#   ll[[length(ll)+1]] = geo
# }
# gg = do.call("rbind", ll)
# st_write(gg, "D:/AgroInsider/Clientes/Sussex/marshall.shp")
############# reprocessar evids #################
reprocess_Evid = function(accountID){
URL = "https://api.agroinsider.com/agroinsider/api/agromap/0/internal/evidences-reprocess/B8LPnL!_tsF&pM"
post = POST(file.path(URL, accountID))
print(post)
req = GET(URL)
reqParse = httr::content(req, as="parsed")
print(reqParse)
return(post)
}
# reprocess_Evid(768)
###### confirmar pontos DAP #####
see_DAP_points = function(accountID=753, parcelID=133228, dateStart, dateEnd){
list_dap_t = check_DapDist(accountID, parcelID, dateStart, dateEnd)
list_points = list()
for(i in 1:length(list_dap_t$dap)){
name = names(list_dap_t$dap[i])
df = st_as_sf(list_dap_t$dap[i][[name]],
coords = c("lon", "lat"),
crs = wgs)
list_points[[name]] = df
}
plt = mapview(list_points, na.color="transparent",
map.types=mapviewGetOption("basemaps")[4])
return(plt)
}
# map = see_DAP_points(753, 133228, "2023-01-01", "2024-12-31")
# map
# add Area and calculate
addArea_wgs = function(in_shp){
sp_utm = projectUTM(in_shp)
sp_utm$Area = as.numeric(st_area(sp_utm))/10000
return(projectWGS(sp_utm))
}
# cria tabela de herdades e areas de OS
allFarms_OS = function(outfold="D:/AgroInsider/Projectos/Temp_Folder/allFarms"){
farms = check_CO2Farms(1, 1000)
vec = c()
for(i in 1:nrow(farms)){
print(c(farms$organizationName[i], farms$parcelName[i]))
info = check_ProjInfo(farms$parcelID[i])
gjson = file.path(outfold, "herdade.geojson")
try({
download.file(info[[1]]$environmentalIndicators[[1]]$data_cloud_link,
gjson)
enc = readr::guess_encoding(gjson)[1,]$encoding
print(enc)
if(! enc %in% c("UTF-8")){
# enc = "WINDOWS-1252"
# read json with enconding
raw_content = readLines(gjson)
aux_os = fromJSON(raw_content)$features$properties$OS
#shp = st_read(gjson, options = paste0("ENCODING=", enc))
shp = st_read(gjson)
shp$OS = aux_os
shp$area = terra::expanse(vect(shp))
# as.numeric(st_area(utm_read))/10000
vec = c(vec, unique(shp$OS))
print(unique(shp$OS))
file.remove(gjson)
}else{
# enc = "UTF-8"
# read json with enconding
#raw_content = readLines(gjson)
#aux_os = fromJSON(raw_content)$features$properties$OS
shp = st_read(gjson, options = paste0("ENCODING=", enc))
#shp$OS = aux_os
shp$area = terra::expanse(vect(shp))
# as.numeric(st_area(utm_read))/10000
vec = c(vec, unique(shp$OS))
print(unique(shp$OS))
file.remove(gjson)
}
})
}
vec = unique(vec)
vec = vec[order(vec)]
df = data.frame(Ocup = vec)
for(i in 1:nrow(farms)){
print(c(farms$organizationName[i], farms$parcelName[i]))
farm_name = gsub("_herdade", "", farms$parcelName[i])
farm_name = gsub("_finca", "", farm_name)
org_num = strsplit(farms$organizationName[i], " ")[[1]][2]
name_out = paste(org_num, farm_name, sep = "_")
info = check_ProjInfo(farms$parcelID[i])
gjson = file.path(outfold, "herdade.geojson")
try({
download.file(info[[1]]$environmentalIndicators[[1]]$data_cloud_link,
gjson)
enc = readr::guess_encoding(gjson)[1,]$encoding
print(enc)
if(! enc %in% c("UTF-8")){
# enc = "WINDOWS-1252"
# read json with enconding
raw_content = readLines(gjson)
aux_os = fromJSON(raw_content)$features$properties$OS
#shp = st_read(gjson, options = paste0("ENCODING=", enc))
shp = st_read(gjson)
shp$OS = aux_os
shp$area = terra::expanse(vect(shp))/10000
# as.numeric(st_area(utm_read))/10000
}else{
# enc = "UTF-8"
# read json with enconding
#raw_content = readLines(gjson)
#aux_os = fromJSON(raw_content)$features$properties$OS
shp = st_read(gjson, options = paste0("ENCODING=", enc))
#shp$OS = aux_os
shp$area = terra::expanse(vect(shp))/10000
# as.numeric(st_area(utm_read))/10000
}
file.remove(gjson)
df[[name_out]] = 0
for(o in unique(shp$OS)){
aux_shp = shp[shp$OS==o,]
area = round(sum(aux_shp$area), 2)
df[df$Ocup == o, name_out] = area
}
})
}
write.table(df, file.path(outfold, "allOS.csv"), row.names = F, sep =";")
}
# apanha os quadrados de verificação
get_verificationCells = function(projID){
URL = paste0("https://api.agroinsider.com/agroinsider/api/agromap/0/internal/projects/B8LPnL!_tsF&pM/",
projID, "/snapshot" )
req = GET(URL)
if(is.null(error_code(req))){
return(NULL)
}
# ler dados
reqParse = httr::content(req, as="parsed")
reqParse = parse_null(reqParse, accountID)
if(! "verificationCells" %in% names(reqParse) ){
return(NULL)
}
vercells = reqParse$verificationCells
# geo = jsonlite::toJSON(vercells$geojsonCells, auto_unbox = TRUE, pretty = TRUE)
geo = geojsonsf::geojson_sf(jsonlite::toJSON(vercells$geojsonCells$features, auto_unbox = TRUE, digits = 6))
geo = geo[geo$polyID %in% unlist(vercells$selectedIdsPolygon),]
geo = geo[, !(names(geo) %in% c("split"))]
return(geo)
}
# gg = get_EvidPoints(588, 133892, '2022-01-01', '2025-12-31', "D:/AgroInsider/Projectos/Temp_Folder/evidCheck/")
# 133431
# cc = check_Parcel(133441)$poly
# st_write(st_as_sfc(cc, st_crs(4326)), "D:/AgroInsider/Projectos/Temp_Folder/sagol.shp")
no_clouds = function(df_mix_all){
vec_remove1 = c()
for(r in 2:(nrow(df_mix_all)-1)){
ponto = as.numeric(df_mix_all[r,2])
ponto_mais = as.numeric(df_mix_all[r+1,2])
ponto_menos = as.numeric(df_mix_all[r-1,2])
data_n = as.numeric(df_mix_all[r,1])
data_mais = as.numeric(df_mix_all[r+1,1])
data_menos = as.numeric(df_mix_all[r-1,1])
if((ponto-ponto_menos<=(-0.05)) & (data_n-data_mais<=10)){
if((ponto-ponto_mais<=(-0.05)) & (data_menos-data_n<=10)){
#value=tab_1[row,1]
vec_remove1 = c(vec_remove1, r)
}
}
}
if(length(vec_remove1)>0){
df_mix_all=df_mix_all[-vec_remove1,]
}
# if(nrow(df_mix_all[-c(which(df_mix_all$NDWI>0.49)),])!=0){
#   df_mix_all = df_mix_all[-c(which(df_mix_all$NDWI>0.49)),]
# }
#encontra o valor da variavel a inserir no criterio seguinte
df_mix_all$difindex=abs(df_mix_all$NDVI-df_mix_all$NDWI)
corr_index = cor(df_mix_all$NDVI, df_mix_all$NDWI)
per_dif = quantile(df_mix_all$difindex, abs(corr_index))
df_mix_all$temp_ndwi=df_mix_all$NDWI+per_dif
#aplicar criterio de escolha de datas
df_mix_all$dif = abs(df_mix_all$NDVI-df_mix_all$temp_ndwi)
df_mix_all = subset(df_mix_all, dif<0.1)
df_mix_all=df_mix_all[order(df_mix_all$Date),]
row.names(df_mix_all) <- NULL
vec_remove1 = c()
for(r in 2:(nrow(df_mix_all)-1)){
ponto = as.numeric(df_mix_all[r,2])
ponto_mais = as.numeric(df_mix_all[r+1,2])
ponto_menos = as.numeric(df_mix_all[r-1,2])
data_n = as.numeric(df_mix_all[r,1])
data_mais = as.numeric(df_mix_all[r+1,1])
data_menos = as.numeric(df_mix_all[r-1,1])
if((ponto-ponto_menos<=(-0.05)) & (data_n-data_mais<=10)){
if((ponto-ponto_mais<=(-0.05)) & (data_menos-data_n<=10)){
#value=tab_1[row,1]
vec_remove1 = c(vec_remove1, r)
}
}
}
if(length(vec_remove1)>0){
df_mix_all=df_mix_all[-vec_remove1,]
}
return(df_mix_all)
}
# a melhor
no_cloudsParcel = function(df_c){
df_c$NDVI = as.numeric(df_c$NDVI)
df_c$NDWI = as.numeric(df_c$NDWI)
if(nrow(df_c[-c(which(df_c$NDWI>0.49)),])!=0){
df_c = df_c[-c(which(df_c$NDWI>0.49)),]
}
# df_c = df_c[-c(which(df_c$NDWI>df_c$NDVI)),]
vec_remove1 = c()
for(r in 2:(nrow(df_c)-1)){
ponto = as.numeric(df_c[r,2])
ponto_mais = as.numeric(df_c[r+1,2])
ponto_menos = as.numeric(df_c[r-1,2])
data_n = as.numeric(df_c[r,1])
data_mais = as.numeric(df_c[r+1,1])
data_menos = as.numeric(df_c[r-1,1])
if((ponto-ponto_menos<=(-0.05)) & (data_n-data_mais<=10)){
if((ponto-ponto_mais<=(-0.05)) & (data_menos-data_n<=10)){
#value=tab_1[row,1]
vec_remove1 = c(vec_remove1, r)
}
}
}
if(length(vec_remove1)>0){
df_c=df_c[-vec_remove1,]
}
#encontra o valor da variavel a inserir no criterio seguinte
df_c$difindex = abs(df_c$NDVI-df_c$NDWI)
corr_index = cor(df_c$NDVI, df_c$NDWI)
if(corr_index<=0){
df_c$diff1 = df_c$NDVI - df_c$NDWI
df_c$NDWI_temp = df_c$NDWI + median(df_c$diff1)
df_c$diff2 = abs(df_c$NDVI - df_c$NDWI_temp)
df_c = df_c[df_c$diff2 < 0.2,]
df_c$difindex=abs(df_c$NDVI-df_c$NDWI)
corr_index = cor(df_c$NDVI, df_c$NDWI)
per_dif = quantile(df_c$difindex, corr_index)
df_c$temp_ndwi=df_c$NDWI+per_dif
df_c$dif=abs(df_c$NDVI-df_c$temp_ndwi)
df_c=subset(df_c, dif<0.1)
df_c=df_c[order(df_c$Date),]
row.names(df_c) = NULL
}else{
per_dif = quantile(df_c$difindex, corr_index)
df_c$temp_ndwi=df_c$NDWI+per_dif
#aplicar criterio de escolha de datas
df_c$dif=abs(df_c$NDVI-df_c$temp_ndwi)
df_c=subset(df_c, dif<0.1)
df_c=df_c[order(df_c$Date),]
row.names(df_c) = NULL
}
vec_remove1 = c()
for(r in 2:(nrow(df_c)-1)){
ponto = as.numeric(df_c[r,2])
ponto_mais = as.numeric(df_c[r+1,2])
ponto_menos = as.numeric(df_c[r-1,2])
data_n = as.numeric(df_c[r,1])
data_mais = as.numeric(df_c[r+1,1])
data_menos = as.numeric(df_c[r-1,1])
if((ponto-ponto_menos<=(-0.05)) & (data_n-data_mais<=10)){
if((ponto-ponto_mais<=(-0.05)) & (data_menos-data_n<=10)){
#value=tab_1[row,1]
vec_remove1 = c(vec_remove1, r)
}
}
}
if(length(vec_remove1)>0){
df_c=df_c[-vec_remove1,]
}
return(df_c)
}
no_cloudsParcel_new = function(df_mix_all){
df_mix_all$NDVI = as.numeric(df_mix_all$NDVI)
df_mix_all$NDWI = as.numeric(df_mix_all$NDWI)
if(nrow(df_mix_all[-c(which(df_mix_all$NDWI>0.49)),])!=0){
df_mix_all = df_mix_all[-c(which(df_mix_all$NDWI>0.49)),]
}
vec_remove1 = c()
for(r in 2:(nrow(df_mix_all)-1)){
ponto = as.numeric(df_mix_all[r,2])
ponto_mais = as.numeric(df_mix_all[r+1,2])
ponto_menos = as.numeric(df_mix_all[r-1,2])
data_n = as.numeric(df_mix_all[r,1])
data_mais = as.numeric(df_mix_all[r+1,1])
data_menos = as.numeric(df_mix_all[r-1,1])
if((ponto-ponto_menos<=(-0.05)) & (data_n-data_mais<=10)){
if((ponto-ponto_mais<=(-0.05)) & (data_menos-data_n<=10)){
#value=tab_1[row,1]
vec_remove1 = c(vec_remove1, r)
}
}
}
if(length(vec_remove1)>0){
df_mix_all=df_mix_all[-vec_remove1,]
}
df_mix_all$diff1 = df_mix_all$NDVI - df_mix_all$NDWI
df_mix_all$NDWI_temp = df_mix_all$NDWI + median(df_mix_all$diff1)
df_mix_all$diff2 = abs(df_mix_all$NDVI - df_mix_all$NDWI_temp)
df_mix_all = df_mix_all[df_mix_all$diff2 < 0.2,]
df_mix_all$difindex=abs(df_mix_all$NDVI-df_mix_all$NDWI)
corr_index = cor(df_mix_all$NDVI, df_mix_all$NDWI)
per_dif = quantile(df_mix_all$difindex, corr_index)
df_mix_all$temp_ndwi=df_mix_all$NDWI+per_dif
df_mix_all$dif=abs(df_mix_all$NDVI-df_mix_all$temp_ndwi)
df_mix_all=subset(df_mix_all, dif<0.1)
df_mix_all=df_mix_all[order(df_mix_all$Date),]
row.names(df_mix_all) = NULL
vec_remove1 = c()
for(r in 2:(nrow(df_mix_all)-1)){
ponto = as.numeric(df_mix_all[r,2])
ponto_mais = as.numeric(df_mix_all[r+1,2])
ponto_menos = as.numeric(df_mix_all[r-1,2])
data_n = as.numeric(df_mix_all[r,1])
data_mais = as.numeric(df_mix_all[r+1,1])
data_menos = as.numeric(df_mix_all[r-1,1])
if((ponto-ponto_menos<=(-0.05)) & (data_n-data_mais<=10)){
if((ponto-ponto_mais<=(-0.05)) & (data_menos-data_n<=10)){
#value=tab_1[row,1]
vec_remove1 = c(vec_remove1, r)
}
}
}
if(length(vec_remove1)>0){
df_mix_all=df_mix_all[-vec_remove1,]
}
return(df_mix_all)
}
plot_OptIndex = function(df, x_var, y_var, x_lab, y_lab, title, date_breaks){
p_par = ggplot()+
geom_line(data = df, aes(x=.data[[x_var]], y = .data[[y_var]], colour = y_var),
color="darkgreen", size = 2)+
ylim(0, max(df[y_var])+0.1)+
theme_bw() +
theme(plot.background = element_rect(colour = "white"),
panel.grid = element_line())+
theme(axis.text.x = element_text(angle=30, hjust=1, size=8))+
theme(plot.title = element_text(hjust=c(0.5)))+
scale_x_date(date_labels = "%b-%d-%Y", date_breaks = date_breaks) +
labs(x = x_lab, y = y_lab, title = title)
print(p_par)
return(p_par)
}
# df_list = dfs_anos; x_var = "yday"; y_var = "NDVI"; color_var="year"; x_lab=""; y_lab="NDVI"; title="Pivot 1 - Mencoca Montoito";
# date_breaks = "2 weeks"; size=length(anos)
plot_OptIndex_multi = function(df_list, x_var, y_var, color_var, x_lab, y_lab, title, date_breaks, size){
val = names(df_list)
#palete = matlab.like(5)
palete = brewer.pal(size, "Set1")
df_list = do.call("rbind", df_list)
df_list[[color_var]] = as.factor(df_list[[color_var]])
#df <- data.frame(x = 1:5, color = palete)
# # Plot the colors as a bar plot
# ggplot(df, aes(x = x, y = 1, fill = color)) +
#   geom_tile() +  # Use tile to show colors
#   scale_fill_identity() +  # Use the color values directly
#   theme_void() +  # Remove background and axes
#   labs(title = "Color Ramp Gradient") +
#   theme(plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
#
# plot(palete)
# palete = RColorBrewer::brewer.pal(n = 8, name = 'YlOrBr')
p_par = ggplot()
max = max(df_list[y_var])
# max = 0
# for(i in 1:length(df_list)){
#   df = df_list[[i]]
#   if(max(df[y_var]) > max){
#     max = max(df[y_var])
#   }
#
#   p_par = p_par +
#     geom_line(data = df, aes(x=.data[[x_var]], y = .data[[y_var]], colour = color_var),
#               color = palete[i], size = 2)
# }
p_par = p_par +
geom_line(data = df_list, aes(x=.data[[x_var]], y = .data[[y_var]], color = .data[[color_var]]),
size = 2)+
ylim(0, max(df_list[y_var])+0.1)+
scale_color_manual(values = palete, labels = val)+
theme_bw() +
theme(plot.background = element_rect(colour = "white"),
panel.grid = element_line())+
theme(axis.text.x = element_text(angle=30, hjust=1, size=8))+
theme(plot.title = element_text(hjust=c(0.5)))+
#scale_x_date(date_labels = "%b-%d-%Y", date_breaks = date_breaks) +
labs(x = x_lab, y = y_lab, title = title)
print(p_par)
return(p_par)
}
dateEnd = as.Date(dateEnd) + 1
URL="https://api.agroinsider.com/agroinsider/api/agromap/0/parcel/images/stats/B8LPnL!_tsF&pM/"
URL=str_c(URL,parcelID,"/",band,"/",dateStart,"/",dateEnd)
req=GET(URL)
if(is.null(error_code(req))){
return(NULL)
}
reqParse = httr::content(req, as="parsed")
reqParse = parse_null(reqParse, parcelID)
reqParse
for(i in 1:length(reqParse)){
reqParse[[i]] = reqParse[[i]][names(reqParse[[i]]) %in% "clusters" == FALSE]
}
df_out = reqParse_toDF(reqParse)
df_out
View(df_out)
names(df_out)
band="RADAR_VH"
URL="https://api.agroinsider.com/agroinsider/api/agromap/0/parcel/images/stats/B8LPnL!_tsF&pM/"
URL=str_c(URL,parcelID,"/",band,"/",dateStart,"/",dateEnd)
req=GET(URL)
if(is.null(error_code(req))){
return(NULL)
}
reqParse = httr::content(req, as="parsed")
reqParse = parse_null(reqParse, parcelID)
for(i in 1:length(reqParse)){
reqParse[[i]] = reqParse[[i]][names(reqParse[[i]]) %in% "clusters" == FALSE]
}
df_out = reqParse_toDF(reqParse)
names(df_out)
parcelID=131938
band="NDVI"
dateStart="2025-01-01"
dateEnd="2025-02-01"
dateEnd = as.Date(dateEnd) + 1
URL="https://api.agroinsider.com/agroinsider/api/agromap/0/parcel/images/stats/B8LPnL!_tsF&pM/"
URL=str_c(URL,parcelID,"/",band,"/",dateStart,"/",dateEnd)
req=GET(URL)
if(is.null(error_code(req))){
return(NULL)
}
reqParse = httr::content(req, as="parsed")
reqParse = parse_null(reqParse, parcelID)
for(i in 1:length(reqParse)){
reqParse[[i]] = reqParse[[i]][names(reqParse[[i]]) %in% "clusters" == FALSE]
}
df_out = reqParse_toDF(reqParse)
df_out
